{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MxkJoQBkUIHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "ZaTwK7ojXr2F",
        "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.17.0'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MXUkhkMfU4wq"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "colab_type": "code",
        "id": "VYP9cQTWbzuI",
        "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "38vKGE6Nb2RR",
        "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PxVKWXxLbczC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:,2] = le.fit_transform(X[:,2])\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AMXC8-KMVirw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers = [('encoder',OneHotEncoder(), [1])], remainder = 'passthrough')\n",
        "X= np.array(ct.fit_transform(X))\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z-TDt0Y_XEfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling [feqature scalling is compulsory for deep learning]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3dtrScHxXQox"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "ann = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bppGycBXYCQr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "ann.add(Dense(units=6, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JneR0u0sYRTd"
      },
      "outputs": [],
      "source": [
        "ann.add(Dense(units=6, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cn3x41RBYfvY"
      },
      "outputs": [],
      "source": [
        "ann.add(Dense(units=1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fG3RrwDXZEaS"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "nHZ-LKv_ZRb3",
        "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.6957 - loss: 0.6076\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8019 - loss: 0.4678\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7957 - loss: 0.4474\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8043 - loss: 0.4378\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8005 - loss: 0.4289\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8033 - loss: 0.4239\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.8114 - loss: 0.4202\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8112 - loss: 0.4173\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8017 - loss: 0.4134\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8047 - loss: 0.4076\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8116 - loss: 0.3963\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8154 - loss: 0.3814\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8365 - loss: 0.3655\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8430 - loss: 0.3663\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8495 - loss: 0.3545\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8558 - loss: 0.3545\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8464 - loss: 0.3687\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8589 - loss: 0.3495\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8608 - loss: 0.3550\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8567 - loss: 0.3481\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8581 - loss: 0.3513\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8544 - loss: 0.3505\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8583 - loss: 0.3545\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8523 - loss: 0.3505\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8591 - loss: 0.3445\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8544 - loss: 0.3531\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8565 - loss: 0.3508\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8609 - loss: 0.3461\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8598 - loss: 0.3437\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.8577 - loss: 0.3464\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8643 - loss: 0.3397\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8625 - loss: 0.3456\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8559 - loss: 0.3537\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8514 - loss: 0.3678\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.8560 - loss: 0.3449\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8614 - loss: 0.3434\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8592 - loss: 0.3424\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8593 - loss: 0.3463\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8644 - loss: 0.3423\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8571 - loss: 0.3453\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8614 - loss: 0.3394\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8635 - loss: 0.3469\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8671 - loss: 0.3421\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8621 - loss: 0.3567\n",
            "Epoch 45/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8623 - loss: 0.3444\n",
            "Epoch 46/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8595 - loss: 0.3438\n",
            "Epoch 47/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8648 - loss: 0.3331\n",
            "Epoch 48/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8615 - loss: 0.3444\n",
            "Epoch 49/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8577 - loss: 0.3500\n",
            "Epoch 50/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8605 - loss: 0.3450\n",
            "Epoch 51/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8557 - loss: 0.3378\n",
            "Epoch 52/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.8637 - loss: 0.3390\n",
            "Epoch 53/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8544 - loss: 0.3541\n",
            "Epoch 54/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8620 - loss: 0.3441\n",
            "Epoch 55/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8638 - loss: 0.3394\n",
            "Epoch 56/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8643 - loss: 0.3384\n",
            "Epoch 57/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8628 - loss: 0.3420\n",
            "Epoch 58/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8627 - loss: 0.3411\n",
            "Epoch 59/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8578 - loss: 0.3493\n",
            "Epoch 60/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.8628 - loss: 0.3384\n",
            "Epoch 61/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8614 - loss: 0.3432\n",
            "Epoch 62/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.8614 - loss: 0.3430\n",
            "Epoch 63/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8677 - loss: 0.3327\n",
            "Epoch 64/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8562 - loss: 0.3509\n",
            "Epoch 65/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8674 - loss: 0.3312\n",
            "Epoch 66/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.8607 - loss: 0.3470\n",
            "Epoch 67/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8565 - loss: 0.3404\n",
            "Epoch 68/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8676 - loss: 0.3349\n",
            "Epoch 69/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.8634 - loss: 0.3351\n",
            "Epoch 70/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8635 - loss: 0.3440\n",
            "Epoch 71/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.8578 - loss: 0.3509\n",
            "Epoch 72/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8542 - loss: 0.3452\n",
            "Epoch 73/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8654 - loss: 0.3324\n",
            "Epoch 74/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.8666 - loss: 0.3309\n",
            "Epoch 75/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8618 - loss: 0.3377\n",
            "Epoch 76/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8590 - loss: 0.3362\n",
            "Epoch 77/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.8590 - loss: 0.3414\n",
            "Epoch 78/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.8630 - loss: 0.3372\n",
            "Epoch 79/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.8635 - loss: 0.3397\n",
            "Epoch 80/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.8560 - loss: 0.3470\n",
            "Epoch 81/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.8617 - loss: 0.3402\n",
            "Epoch 82/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8591 - loss: 0.3479\n",
            "Epoch 83/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8661 - loss: 0.3320\n",
            "Epoch 84/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8636 - loss: 0.3381\n",
            "Epoch 85/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8588 - loss: 0.3487\n",
            "Epoch 86/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.8569 - loss: 0.3445\n",
            "Epoch 87/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8619 - loss: 0.3391\n",
            "Epoch 88/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.8551 - loss: 0.3510\n",
            "Epoch 89/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.8573 - loss: 0.3410\n",
            "Epoch 90/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.8645 - loss: 0.3329\n",
            "Epoch 91/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8549 - loss: 0.3519\n",
            "Epoch 92/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8705 - loss: 0.3272\n",
            "Epoch 93/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8581 - loss: 0.3414\n",
            "Epoch 94/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8602 - loss: 0.3474\n",
            "Epoch 95/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8615 - loss: 0.3433\n",
            "Epoch 96/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.8578 - loss: 0.3497\n",
            "Epoch 97/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.8550 - loss: 0.3459\n",
            "Epoch 98/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.8601 - loss: 0.3452\n",
            "Epoch 99/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.8663 - loss: 0.3329\n",
            "Epoch 100/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8609 - loss: 0.3373\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1a4df653f80>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann.fit(X_train, y_train , batch_size= 32, epochs= 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "<span style=\"color:orange\">Test Scenerio: A new customer walks in to the bank</span>\n",
        "\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "2d8IoCCkeWGL",
        "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[[0.0231461]]\n"
          ]
        }
      ],
      "source": [
        "y_test_single = [[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]] #predict method expects 2d array\n",
        "y_pred = ann.predict(sc.transform(y_test_single)) #apply same scale to input\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[False]]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred> 0.5) # adding a condition to get binary output. if its larger than 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "[[0.0231461]]\n"
          ]
        }
      ],
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))) #same code in single line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step\n",
            "[[0.33998486]\n",
            " [0.30538526]\n",
            " [0.14981891]\n",
            " ...\n",
            " [0.25662822]\n",
            " [0.14824907]\n",
            " [0.15429823]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "print(y_pred) #probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = (y_pred> 0.5) # adding a condition to get binary output. if its larger than 0.5\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "colab_type": "code",
        "id": "nIyEeQdRZwgs",
        "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(np.column_stack((y_pred>0., y_test))) #seeing pred and test value side by side"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "ci6K_r6LaF6P",
        "outputId": "4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1511   84]\n",
            " [ 195  210]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plotting confution matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"test\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check Accuracy of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8605"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "artificial_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
